Index: ../pythonProject/Algorytm_SVM.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/../pythonProject/Algorytm_SVM.py b/../pythonProject/Algorytm_SVM.py
deleted file mode 100644
--- a/../pythonProject/Algorytm_SVM.py	
+++ /dev/null	
@@ -1,99 +0,0 @@
-import numpy as np
-import pandas as pd
-from sklearn.base import BaseEstimator, ClassifierMixin
-from sklearn.preprocessing import LabelEncoder
-from sklearn.preprocessing import StandardScaler
-from sklearn.datasets import make_classification
-from sklearn.model_selection import train_test_split
-from sklearn.metrics import accuracy_score
-from sklearn import naive_bayes
-from sklearn.neighbors import KNeighborsClassifier
-from sklearn.svm import SVC
-from itertools import combinations
-
-dane_rzeczywiste=pd.read_csv('Iris.csv') #załadowanie danych z exella, wyswietlenie ich stat, usuniecie columny id
-#print(dane_rzeczywiste)
-#print(dane_rzeczywiste.describe())
-dane_rzeczywiste.drop(columns = ['Id'], axis=1, inplace=True)
-#print(dane_rzeczywiste)
-
-# definiujemy SVM liniowego
-class aSVM(BaseEstimator):
-    def __init__(self, learning_rate=0.005, lambda_param=0.01, n_iters=1000): #inicjalizacja obiektu
-        self.lr = learning_rate
-        self.lambda_param = lambda_param
-        self.n_iters = n_iters
-        self.w = None #przechowywanie wag
-        self.b = None #przechowywanie obciazenia
-
-    def fit(self, X,y): #trenowanie modelu
-        n_samples, n_features = X.shape
-
-        self.w = np.zeros(n_features) #self.w - wektor zer o dlugosci n_features
-        self.b = 0 #obiciazenie = 0, obciażenie to bias?
-
-        for _ in range(self.n_iters):
-            for i in range(n_samples):
-                if y[i] * (np.dot(X[i],self.w) - self.b) >=1: # czy wynik klasyfikacji jest wiekszy od 1
-                    self.w -= self.lr * (2 * self.lambda_param * self.w) #if poprawna klasyfikacja, aktualizauje sie waga
-                else:
-                    self.w -= self.lr * (2 * self.lambda_param * self.w -np.dot(X[i],y[i])) #if niepoprawna klasyfikacja mniejsza od 1, to aktualizacja wagi o obciążenia
-                    self.b -= self.lr * y[i]
-    def predict(self, X): #przewiduje klas dla nowych X na podstawie self.w i self.b
-        pred = np.sign(np.dot(X, self.w) - self.b) #sign zwraca 1 dla dodatnych lub -1 dla ujemnych, wynik to przewidywanie etykiet
-        return pred
-
-y_rz = dane_rzeczywiste['Species']
-X_rz = dane_rzeczywiste.drop(['Species'], axis=1)
-
-etykiety = LabelEncoder() #zmiana danych tekstowych na dane liczbowe: 0,1,2
-y_rz=etykiety.fit_transform(y_rz)
-
-scaler = StandardScaler() #skaluje atrybuty
-X_rz = scaler.fit_transform(X_rz)
-
-X, y = make_classification(n_samples=150, n_informative=3, n_classes=3, n_features=4,n_redundant=1,  random_state=5) #dane syntetyczne
-X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4) #podział danych syntetycznych
-X_rz_train, X_rz_test, y_rz_train, y_rz_test = train_test_split(X_rz, y_rz, test_size=0.3, random_state=4) #podział danych rzezywistych
-
-#TESTOWANIE CZY SVM DAJE TAKIE SAME WYNIKI JAK TEN Z BIBLIOTEKI
-X_svm_test, y_svm_test = make_classification(n_samples=150, n_informative=2, n_classes=2, n_features=4,n_redundant=1,  random_state=50) #dane testowe dla liniowego SVM
-X_svm_test_train, X_svm_test_test, y_svm_test_train, y_svm_test_test = train_test_split(X_svm_test, y_svm_test, test_size=0.3, random_state=4) # podzial na train i test
-
-svc = SVC()
-svc.fit(X_svm_test_train, y_svm_test_train) #uczenie
-y_pred=svc.predict(X_svm_test_test)
-acc = accuracy_score(y_svm_test_test,y_pred)
-print('Accurancy liniowego SVM z biblioteki: ', acc)
-
-svc2 = aSVM()
-svc2.fit(X_svm_test_train, y_svm_test_train)
-y_pred2 = svc2.predict(X_svm_test_test)
-acc2 = accuracy_score(y_svm_test_test, y_pred)
-print('Accurancy zdefiniowanego liniowego SVM', acc2)
-############################################################################################
-print('dane rzeczywiste: ', y_rz)
-print('dane syntetyczne: ', y)
-#One vs One, N(N-1)/2
-class one_vs_one(BaseEstimator):
-    def __init__(self):
-        self.classifiers = []
-    def fit(self, X, y):
-        self.classes = np.unique(y).flatten()
-
-        for class_a, class_b in combinations(self.classes, 2): #wybiera wszystkie możliwe pary
-            szablon = (y==class_a) | (y == class_b) #True jeśli należą do jednej z dwóch klas a lub b wtedy True jak nie to False
-            para_X = X[szablon]
-            para_y = y[szablon]
-
-            classif = aSVC()
-            classif.fit(para_X, para_y)
-            self.classifiers.append(class_a,class_b, classif) #dodaje do arraya classufiers
-    def predict(self, X): #glosowanie wiekszosciowe ta klasa co ma najwiecej glosow wygrywa, iteracja po all binarnych klasyfikatorach wytrenowanych na parach klas i zbieramy predykcje wskazujaca na konkretna klase
-        xd = xd
-
-
-
-
-
-
Index: .idea/.gitignore
===================================================================
diff --git a/.idea/.gitignore b/.idea/.gitignore
new file mode 100644
--- /dev/null	
+++ b/.idea/.gitignore	
@@ -0,0 +1,3 @@
+# Default ignored files
+/shelf/
+/workspace.xml
Index: ../pythonProject/.idea/pythonProject.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/../pythonProject/.idea/pythonProject.iml b/../pythonProject/.idea/pythonProject.iml
new file mode 100644
--- /dev/null	
+++ b/../pythonProject/.idea/pythonProject.iml	
@@ -0,0 +1,10 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<module type="PYTHON_MODULE" version="4">
+  <component name="NewModuleRootManager">
+    <content url="file://$MODULE_DIR$">
+      <excludeFolder url="file://$MODULE_DIR$/venv" />
+    </content>
+    <orderEntry type="inheritedJdk" />
+    <orderEntry type="sourceFolder" forTests="false" />
+  </component>
+</module>
\ No newline at end of file
Index: ../pythonProject/TEST41.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/../pythonProject/TEST41.py b/../pythonProject/TEST41.py
--- a/../pythonProject/TEST41.py	
+++ b/../pythonProject/TEST41.py	
@@ -1,0 +1,38 @@
+from sklearn.naive_bayes import GaussianNB
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.tree import DecisionTreeClassifier
+import numpy as np
+from sklearn.model_selection import RepeatedStratifiedKFold
+from sklearn.metrics import accuracy_score
+
+clfs = {
+    'GNB': GaussianNB(),
+    'kNN': KNeighborsClassifier(),
+    'CART': DecisionTreeClassifier(random_state=1),
+}
+
+datasets = ['appendicitis', 'balance', 'banana', 'bupa', 'glass',
+            'iris', 'led7digit', 'magic', 'phoneme', 'ring', 'segment',
+            'sonar', 'spambase', 'texture', 'twonorm', 'wdbc',
+            'winequality-red', 'winequality-white', 'yeast']
+
+n_datasets = len(datasets)
+n_splits = 5
+n_repeats = 2
+rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=1)
+
+scores = np.zeros((len(clfs), n_datasets, n_splits * n_repeats))
+
+for data_id, dataset_name in enumerate(datasets):
+    dataset = np.loadtxt(f"{dataset_name}.csv", delimiter=",")
+    X = dataset[:, :-1]
+    y = dataset[:, -1].astype(int)
+
+    for fold_id, (train, test) in enumerate(rskf.split(X, y)):
+        for clf_id, clf_name in enumerate(clfs):
+            clf = clfs[clf_name]
+            clf.fit(X[train], y[train])
+            y_pred = clf.predict(X[test])
+            scores[clf_id, data_id, fold_id] = accuracy_score(y[test], y_pred)
+
+np.save('results.npy', scores)
Index: .idea/inspectionProfiles/Project_Default.xml
===================================================================
diff --git a/.idea/inspectionProfiles/Project_Default.xml b/.idea/inspectionProfiles/Project_Default.xml
new file mode 100644
--- /dev/null	
+++ b/.idea/inspectionProfiles/Project_Default.xml	
@@ -0,0 +1,12 @@
+<component name="InspectionProjectProfileManager">
+  <profile version="1.0">
+    <option name="myName" value="Project Default" />
+    <inspection_tool class="PyUnresolvedReferencesInspection" enabled="true" level="WARNING" enabled_by_default="true">
+      <option name="ignoredIdentifiers">
+        <list>
+          <option value="plot_confusion_matrix" />
+        </list>
+      </option>
+    </inspection_tool>
+  </profile>
+</component>
\ No newline at end of file
Index: .idea/Projekt.iml
===================================================================
diff --git a/.idea/Projekt.iml b/.idea/Projekt.iml
new file mode 100644
--- /dev/null	
+++ b/.idea/Projekt.iml	
@@ -0,0 +1,8 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<module type="PYTHON_MODULE" version="4">
+  <component name="NewModuleRootManager">
+    <content url="file://$MODULE_DIR$" />
+    <orderEntry type="inheritedJdk" />
+    <orderEntry type="sourceFolder" forTests="false" />
+  </component>
+</module>
\ No newline at end of file
Index: .idea/modules.xml
===================================================================
diff --git a/.idea/modules.xml b/.idea/modules.xml
new file mode 100644
--- /dev/null	
+++ b/.idea/modules.xml	
@@ -0,0 +1,8 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="ProjectModuleManager">
+    <modules>
+      <module fileurl="file://$PROJECT_DIR$/.idea/Projekt.iml" filepath="$PROJECT_DIR$/.idea/Projekt.iml" />
+    </modules>
+  </component>
+</project>
\ No newline at end of file
Index: .idea/misc.xml
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
new file mode 100644
--- /dev/null	
+++ b/.idea/misc.xml	
@@ -0,0 +1,4 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.9" project-jdk-type="Python SDK" />
+</project>
\ No newline at end of file
Index: .idea/vcs.xml
===================================================================
diff --git a/.idea/vcs.xml b/.idea/vcs.xml
new file mode 100644
--- /dev/null	
+++ b/.idea/vcs.xml	
@@ -0,0 +1,6 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<project version="4">
+  <component name="VcsDirectoryMappings">
+    <mapping directory="$PROJECT_DIR$/.." vcs="Git" />
+  </component>
+</project>
\ No newline at end of file
Index: .idea/inspectionProfiles/profiles_settings.xml
===================================================================
diff --git a/.idea/inspectionProfiles/profiles_settings.xml b/.idea/inspectionProfiles/profiles_settings.xml
new file mode 100644
--- /dev/null	
+++ b/.idea/inspectionProfiles/profiles_settings.xml	
@@ -0,0 +1,6 @@
+<component name="InspectionProjectProfileManager">
+  <settings>
+    <option name="USE_PROJECT_PROFILE" value="false" />
+    <version value="1.0" />
+  </settings>
+</component>
\ No newline at end of file
Index: ../pythonProject/laby5_1.py
===================================================================
diff --git a/../pythonProject/laby5_1.py b/../pythonProject/laby5_1.py
--- a/../pythonProject/laby5_1.py	
+++ b/../pythonProject/laby5_1.py	
@@ -1,0 +1,65 @@
+import os
+import numpy as np
+from sklearn.naive_bayes import GaussianNB
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.tree import DecisionTreeClassifier
+from sklearn.model_selection import RepeatedStratifiedKFold
+from sklearn.metrics import accuracy_score
+from sklearn import clone
+from scipy import stats
+
+algoritms = {
+    'Gaus': GaussianNB(),
+    'KNB': KNeighborsClassifier(),
+    'Tree': DecisionTreeClassifier()
+}
+datasets = os.listdir('datasets')
+
+n_folds = 2
+n_powt = 5
+n_datasets = len(datasets)
+n_algoritms = len(algoritms)
+print (n_datasets)
+rskf = RepeatedStratifiedKFold(n_splits=n_folds, n_repeats=n_powt, random_state=1)
+
+scores = np.zeros((n_datasets, n_folds*n_powt,n_algoritms))
+print (scores)
+for file_id, file in enumerate(datasets):
+    load = np.loadtxt('datasets/' + file, delimiter=',')
+    X = load[:, : -1]
+    y = load[:, -1]
+    for fold_id, (train, test) in enumerate(rskf.split(X, y)):
+        for clf_id, clf_name in enumerate(algoritms):
+            clf = clone(algoritms[clf_name])
+            clf.fit(X[train], y[train])
+            y_pred = clf.predict(X[test])
+            scores[file_id, fold_id, clf_id] = accuracy_score(y[test], y_pred)
+            print(scores)
+#np.save('results.npy', scores)
+
+#2
+
+dane = np.load('results.npy')[8]
+
+macierz_wielkosci = np.zeros((n_algoritms, n_algoritms))
+macierz_p = np.zeros((n_algoritms, n_algoritms))
+macierz_bool = np.zeros((n_algoritms, n_algoritms)).astype(bool)
+
+for i in range(n_algoritms):
+
+    for j in range(n_algoritms):
+       class_res1 = dane[: , i]
+       class_res2 = dane[:, j]
+       testT, pvalue = stats.ttest_ind(class_res1, class_res2)
+       print(testT, pvalue)
+       macierz_bool[i, j] = (np.mean(class_res1) > np.mean(class_res2))
+       print(macierz_bool)
+
+alpha = 0.05
+staty = pvalue < alpha
+macierz_koncowa = staty * macierz_bool
+print(macierz_koncowa)
+
+
+
+
Index: ../pythonProject/dom3_2.py
===================================================================
diff --git a/../pythonProject/dom3_2.py b/../pythonProject/dom3_2.py
--- a/../pythonProject/dom3_2.py	
+++ b/../pythonProject/dom3_2.py	
@@ -1,0 +1,68 @@
+import os
+
+import numpy as np
+from sklearn import clone
+from sklearn.metrics import accuracy_score
+from sklearn.model_selection import RepeatedStratifiedKFold
+from sklearn.naive_bayes import GaussianNB
+from sklearn.neighbors import KNeighborsClassifier
+from sklearn.tree import DecisionTreeClassifier
+from scipy import stats
+
+# Zad1
+#
+datasets = ['appendicitis.csv', 'balance.csv', 'banana.csv', 'bupa.csv', 'glass.csv', 'iris.csv',
+            'led7digit.csv', 'magic.csv', 'phoneme.csv', 'ring.csv', 'segment.csv', 'sonar.csv',
+            'spambase.csv', 'texture.csv', 'twonorm.csv', 'wdbc.csv', 'winequality-red.csv',
+            'winequality-white.csv', 'yeast.csv']
+
+
+
+clfs = {
+    GaussianNB(),
+    KNeighborsClassifier(),
+    DecisionTreeClassifier()
+}
+
+# s = 2
+# r = 5
+#
+# rskf = RepeatedStratifiedKFold(n_splits=s, n_repeats=r, random_state=1)
+#
+# scores1 = np.zeros((len(datasets), s * r, len(clfs)))
+#
+# for fileID, dataset in enumerate(datasets):
+#     data = np.loadtxt(fname='datasets/%s' % dataset, delimiter=",")
+#     X = data[:, :-1]
+#     y = data[:, -1]
+#     for fold_id, (train, test) in enumerate(rskf.split(X, y)):
+#         for clf_id, clf in enumerate(clfs):
+#             y_pred = clone(clf).fit(X[train], y[train]).predict(X[test])
+#             scores1[fileID, fold_id, clf_id] = accuracy_score(y[test], y_pred)
+#
+# np.save('wyniki.npy', scores1)
+# print('Zad1')
+#
+
+
+# Zad2
+
+res = np.load('wyniki.npy')
+print(res)
+res_one = res[8]
+
+alfa = 0.05
+t_statistic = np.zeros(((len(clfs)), (len(clfs))))
+p_value = np.zeros(((len(clfs)), (len(clfs))))
+better = np.zeros(((len(clfs)), (len(clfs)))).astype(bool)
+
+for i in range(len(clfs)):
+    for j in range(len(clfs)):
+        t_statistic[i, j], p_value[i, j] = stats.ttest_ind(res_one[:, i], res_one[:, j])
+        better[i, j] = np.mean(res_one[:, i]) > np.mean(res_one[:, j])
+
+significant = p_value < alfa
+sign_better = significant * better
+
+print(significant)
+print(sign_better)
